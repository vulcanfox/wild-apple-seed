{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7908534",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "import numpy as np\n",
    "from scipy.sparse import hstack\n",
    "import nltk as nltk\n",
    "from nltk import word_tokenize          \n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('vader_lexicon')\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "from gensim.matutils import any2sparse\n",
    "from gensim.models import LdaModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba379ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading files\n",
    "train_files = [\n",
    "    'data/FiQA_ABSA_task1/task1_headline_ABSA_train.json',\n",
    "    'data/FiQA_ABSA_task1/task1_post_ABSA_train.json'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5759a312",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def load_fiqa_sa_from_json(json_files):\n",
    "    train_text = []\n",
    "    train_labels = []\n",
    "\n",
    "    for file in json_files:\n",
    "        with open(file, 'r', encoding='UTF-8') as handle:\n",
    "            dataf = json.load(handle)\n",
    "        dataf_text = [dataf[k][\"sentence\"] for k in dataf.keys()]\n",
    "        train_text.extend(dataf_text)\n",
    "        dataf_labels = [float(dataf[k][\"info\"][0][\"sentiment_score\"]) for k in dataf.keys()]\n",
    "        train_labels.extend(dataf_labels)\n",
    "    train_text = np.array(train_text)\n",
    "    train_labels = np.array(train_labels)\n",
    "    return train_text, train_labels\n",
    "\n",
    "\n",
    "def threshold_scores(scores):\n",
    "    \"\"\"\n",
    "    Convert sentiment scores to discrete labels.\n",
    "    0 = negative.\n",
    "    1 = neutral.\n",
    "    2 = positive.\n",
    "    \"\"\"\n",
    "    labels = []\n",
    "    for score in scores:\n",
    "        if score < -0.2:\n",
    "            labels.append(0)\n",
    "        elif score > 0.2:\n",
    "            labels.append(2)\n",
    "        else:\n",
    "            labels.append(1)\n",
    "            \n",
    "    return np.array(labels)\n",
    "\n",
    "\n",
    "all_text, all_labels = load_fiqa_sa_from_json(train_files)\n",
    "    \n",
    "print(f'Number of instances: {len(all_text)}')\n",
    "print(f'Number of labels: {len(all_labels)}')\n",
    "\n",
    "all_labels = threshold_scores(all_labels)\n",
    "print(f'Number of negative labels: {np.sum(all_labels==0)}')\n",
    "print(f'Number of neutral labels: {np.sum(all_labels==1)}')\n",
    "print(f'Number of positive labels: {np.sum(all_labels==2)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47a92deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training, validation, testing sets.\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split test data from training data\n",
    "train__docs, test__docs, train_labels, test_labels = train_test_split(\n",
    "    all_text, \n",
    "    all_labels, \n",
    "    test_size=0.2, \n",
    "    stratify=all_labels\n",
    ")\n",
    "\n",
    "# Split validation data from training data\n",
    "train__docs, val_documents, train_labels, val_labels = train_test_split(\n",
    "    train__docs, \n",
    "    train_labels, \n",
    "    test_size=0.2, \n",
    "    stratify=train_labels\n",
    ")\n",
    "\n",
    "print(f'Number of training instances = {len(train__docs)}')\n",
    "print(f'Number of validation instances = {len(val_documents)}')\n",
    "print(f'Number of test instances = {len(test__docs)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "705da643",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print example doc\n",
    "print(f'What does one instance look like from the training set? \\n\\n{train__docs[234]}')\n",
    "print(f'...and here is its corresponding label \\n\\n{train_labels[234]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c42859",
   "metadata": {},
   "source": [
    "# 1. Preprocessing using  lemmatization\n",
    "We create a lemmatizer tokenizer that reduces words to their root forms. This reduces the vocabulary size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ae5080",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create a lemmaTokenizer class that applies lemmatization when tokenizing.\n",
    "class LemmaTokenizer(object):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.wnl = WordNetLemmatizer()\n",
    "        \n",
    "    def __call__(self, _docs):\n",
    "        return [self.wnl.lemmatize(self.wnl.lemmatize(self.wnl.lemmatize(tok, pos='n'), pos='v'), pos='a') for tok in word_tokenize(_docs)]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a59ac4fd",
   "metadata": {},
   "source": [
    "# 2.1 Using bi-grams + unigrams as feature\n",
    "We apply our tokenizer and set it to allow ngram features (both unigrams and bigrams). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1969d4ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(tokenizer=LemmaTokenizer(), ngram_range=(1,2))\n",
    "vectorizer.fit(train__docs)\n",
    "X_train = vectorizer.transform(train__docs)\n",
    "X_val = vectorizer.transform(val_documents)\n",
    "X_test__docs = vectorizer.transform(test__docs)\n",
    "# Let's look at some of the features.\n",
    "print(list(vectorizer.vocabulary_)[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f2337e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking full vocabulary size:\n",
    "print('Full vocabulary size: {}'.format(len(vectorizer.vocabulary_)))\n",
    "vocabulary = vectorizer.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7756fa64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's fit our data to the model.\n",
    "classifier = LogisticRegression()\n",
    "classifier.fit(X_train, train_labels)\n",
    "y_val_pred = classifier.predict(X_val)\n",
    "cm = confusion_matrix(val_labels, y_val_pred)\n",
    "cm_display = ConfusionMatrixDisplay(cm).plot()\n",
    "print(classification_report(val_labels, y_val_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b388a23f",
   "metadata": {},
   "source": [
    "# Using POS-NEG lexicon features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa409e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate analyzer\n",
    "analyser = SentimentIntensityAnalyzer()\n",
    "# fetch vocabulary\n",
    "vocabulary = vectorizer.vocabulary_\n",
    "# create empy holders for lexicon scores.\n",
    "lexicon_pos_scores = np.zeros((1, len(vocabulary)))\n",
    "lexicon_neg_scores = np.zeros((1, len(vocabulary)))\n",
    "\n",
    "for i, term in enumerate(vocabulary):\n",
    "    if term in analyser.lexicon and analyser.lexicon[term] > 0:\n",
    "        lexicon_pos_scores[0, i] = 1\n",
    "    elif term in analyser.lexicon and analyser.lexicon[term] < 0:\n",
    "        lexicon_neg_scores[0, i] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dab3fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This enables us to get the total positive and total negative counts for each set:\n",
    "lexicon_pos_train = np.sum(X_train.multiply(lexicon_pos_scores), axis=1)\n",
    "lexicon_pos_val = np.sum(X_val.multiply(lexicon_pos_scores), axis=1)\n",
    "lexicon_pos_test = np.sum(X_test__docs.multiply(lexicon_pos_scores), axis=1)\n",
    "\n",
    "lexicon_neg_train = np.sum(X_train.multiply(lexicon_neg_scores), axis=1)\n",
    "lexicon_neg_val = np.sum(X_val.multiply(lexicon_neg_scores), axis=1)\n",
    "lexicon_neg_test = np.sum(X_test__docs.multiply(lexicon_neg_scores), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe1f6ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = hstack((X_train, lexicon_pos_train, lexicon_neg_train))\n",
    "X_val = hstack((X_val, lexicon_pos_val, lexicon_neg_val))\n",
    "X_test__docs = hstack((X_test__docs, lexicon_pos_test, lexicon_neg_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a73c365c",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = LogisticRegression()\n",
    "classifier.fit(X_train, train_labels)\n",
    "y_val_pred = classifier.predict(X_val)\n",
    "# Checking performance\n",
    "cm = confusion_matrix(val_labels, y_val_pred)\n",
    "cm_display = ConfusionMatrixDisplay(cm).plot()\n",
    "print(classification_report(val_labels, y_val_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5185db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Key part is investigating the errors by looking at the actual values, so let's do that:\n",
    "error_indexes = y_val_pred != val_labels  # let's compare predictions to true values for labels\n",
    "\n",
    "# get the _docs where the classifier made an error:\n",
    "_docs_err = np.array(val_documents)[error_indexes]\n",
    "\n",
    "pred_err = y_val_pred[error_indexes]\n",
    "true_err = np.array(val_labels)[error_indexes]\n",
    "\n",
    "for i in range(10):\n",
    "    print(f'doc: {_docs_err[i]}; true label = {true_err[i]}, prediction = {pred_err[i]}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c971c52d",
   "metadata": {},
   "source": [
    "# Performance on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81143bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's test the performance on the test set.\n",
    "y_test_pred = classifier.predict(X_test__docs)\n",
    "# Checking performance\n",
    "cm = confusion_matrix(test_labels, y_test_pred)\n",
    "cm_display = ConfusionMatrixDisplay(cm).plot()\n",
    "print(classification_report(test_labels, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad9aa047",
   "metadata": {},
   "source": [
    "# 4. Extracting topics using LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaaad88d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First let's get another clean split of the data. \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split test data from training data\n",
    "train__docs, test__docs, train_labels, test_labels = train_test_split(\n",
    "    all_text, \n",
    "    all_labels, \n",
    "    test_size=0.2, \n",
    "    stratify=all_labels\n",
    ")\n",
    "\n",
    "# Split validation data from training data\n",
    "train__docs, val__docs, train_labels, val_labels = train_test_split(\n",
    "    train__docs, \n",
    "    train_labels, \n",
    "    test_size=0.2, \n",
    "    stratify=train_labels \n",
    ")\n",
    "\n",
    "print(f'Number of training instances = {len(train__docs)}')\n",
    "print(f'Number of validation instances = {len(val__docs)}')\n",
    "print(f'Number of test instances = {len(test__docs)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee1d2b43",
   "metadata": {},
   "outputs": [],
   "source": [
    " # We use the function below for tokenization. Does a number of things, including removing small words, deleting words with special chars,  changing uppercase to lowercase, and more.\n",
    "def preprocess(text):\n",
    "    final_results=[]\n",
    "    for token in simple_preprocess(text) : \n",
    "        if token not in STOPWORDS:\n",
    "            final_results.append(WordNetLemmatizer().lemmatize(token, 'v'))\n",
    "    return final_results\n",
    "\n",
    "# Create a list of preprocessed documents\n",
    "processed = []\n",
    "for doc in train__docs:\n",
    "    processed.append(preprocess(doc))\n",
    "print(processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "603dbbda",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.corpora import Dictionary\n",
    "# create a dictionary of word:id key/val pairs.\n",
    "dictionary = Dictionary(processed) \n",
    "print(dictionary)\n",
    "\n",
    "bow_corpus = [dictionary.doc2bow(doc) for doc in processed]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6adba04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting means of thetas and training the LDA.\n",
    "\n",
    "\n",
    "\n",
    "lda_model =  LdaModel(bow_corpus, \n",
    "                      num_topics=10, \n",
    "                      id2word=dictionary,                                    \n",
    "                      passes=10,\n",
    "                    ) \n",
    "\n",
    "def get_doc_topic_dists(_docs, lda_model):\n",
    "    thetas = []\n",
    "    for i in range(len(_docs)):\n",
    "        # Get the doc\n",
    "        unseen_doc = _docs[i]\n",
    "\n",
    "        # Preprocess for bag of words:\n",
    "        bow_vector = dictionary.doc2bow(preprocess(unseen_doc))\n",
    "\n",
    "        theta_doc = lda_model[bow_vector]\n",
    "\n",
    "        thetas.append(theta_doc)\n",
    "\n",
    "    return thetas\n",
    "\n",
    "thetas = get_doc_topic_dists(val__docs, lda_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1406ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# We will use colours to represent topics.\n",
    "colours = ['blue', 'green', 'red', 'yellow', 'black', 'pink', 'purple',\n",
    "           'orange',  'darkgreen',  'navy', 'crimson']\n",
    "\n",
    "def convert_theta_sparse_to_dense_vector(theta_dist_sparse, num_topics):\n",
    "    theta_dist = np.zeros(num_topics)\n",
    "    \n",
    "    # get active topics\n",
    "    active_topics_for_dist, probs = map(list, zip(*theta_dist_sparse))\n",
    "    \n",
    "    # add to thetas_dist\n",
    "    for i, topic in enumerate(active_topics_for_dist):\n",
    "        if topic >= num_topics:\n",
    "            break\n",
    "            \n",
    "        theta_dist[topic] = probs[i]\n",
    "    \n",
    "    return theta_dist\n",
    "\n",
    "# Create barchart\n",
    "def plot_theta(thetas, i, num__docs, num_topics):\n",
    "    plt.subplot(int((num__docs+1)/2), 2, i+1)\n",
    "    theta_dist = convert_theta_sparse_to_dense_vector(thetas[i], num_topics)\n",
    "    plt.bar(x=np.arange(len(theta_dist)), height=theta_dist, color=colours, tick_label=np.arange(num_topics))\n",
    "    plt.xlabel(\"Topic ID\")\n",
    "    plt.ylabel(\"Probability\")\n",
    "plt.figure(figsize=(20,20))\n",
    "\n",
    "num__docs = 10\n",
    "num_topics = 10\n",
    "counter = 0\n",
    "for i, theta in enumerate(thetas):\n",
    "    if (counter < 10):\n",
    "        plot_theta(thetas, i, num__docs, num_topics)\n",
    "        counter +=1\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11a721b6",
   "metadata": {},
   "source": [
    "# Visualizing topic distributions across labels using validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ffcd72b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge arrays for later \n",
    "arr = val__docs\n",
    "arr_2 = val_labels\n",
    "\n",
    "arrays = [arr,arr_2]\n",
    "new_arr = np.stack(arrays, axis=1)\n",
    "print(new_arr[new_arr[:,1] =='1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20469e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show numbers till 8 decimal points for debugging.\n",
    "np.set_printoptions(precision=8)\n",
    "def get_doc_mean_topics():\n",
    "    # Create a matrix where each row corresponds to a label\n",
    "    mean_thetas = np.zeros((len(['0','1','2']), 10))\n",
    "    label_arr = ['0','1','2']\n",
    "    for label in label_arr:\n",
    "        # call get_doc_topic_dists\n",
    "        thetas_t_sparse = get_doc_topic_dists(val__docs[new_arr[:,1] ==label], lda_model)\n",
    "        # convert to a dense vector\n",
    "        thetas_t = []\n",
    "        for theta_dist_t_sparse in thetas_t_sparse:\n",
    "            if not theta_dist_t_sparse:\n",
    "                continue\n",
    "            thetas_dist = convert_theta_sparse_to_dense_vector(theta_dist_t_sparse, 10)\n",
    "            thetas_t.append(thetas_dist)\n",
    "        # Get the mean theta\n",
    "        mean_theta_t = np.mean(thetas_t, axis=0)\n",
    "        mean_thetas[int(label)] = mean_theta_t\n",
    "        print(mean_thetas[int(label)])\n",
    "    return mean_thetas\n",
    "   \n",
    "mean_arr = get_doc_mean_topics()\n",
    "\n",
    "print(mean_arr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c577386",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_doc_topic_matrix():\n",
    "    # Get mean doc topics dists\n",
    "    mean_thetas = get_doc_mean_topics()\n",
    "    # Let's show a heatmap to see which topics occur the most for different labels\n",
    "    plt.imshow(mean_thetas)\n",
    "    plt.colorbar()\n",
    "    plt.xlabel(\"Topic ID\")\n",
    "    plt.ylabel(\"Class label\")\n",
    "    plt.show()\n",
    "plot_doc_topic_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2a6fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each topic, let's show the words occuring in that topic, so we can identify it.\n",
    "for topic_id, topic in lda_model.print_topics(-1):\n",
    "    print(\"Topic ID: {} \\nAssociated Words:\\n {}\".format(topic_id, topic ))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ee8dae6",
   "metadata": {},
   "source": [
    "# Using test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d83fd00e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge arrays for later \n",
    "arr = test__docs\n",
    "arr_2 = test_labels\n",
    "\n",
    "arrays = [arr,arr_2]\n",
    "new_arr = np.stack(arrays, axis=1)\n",
    "print(new_arr[new_arr[:,1] =='1'])\n",
    "\n",
    "# Show numbers till 8 decimal points for debugging.\n",
    "np.set_printoptions(precision=8)\n",
    "def get_doc_mean_topics():\n",
    "    # Create a matrix where each row corresponds to a label\n",
    "    mean_thetas = np.zeros((len(['0','1','2']), 10))\n",
    "    label_arr = ['0','1','2']\n",
    "    for label in label_arr:\n",
    "        # call get_doc_topic_dists\n",
    "        thetas_t_sparse = get_doc_topic_dists(test__docs[new_arr[:,1] ==label], lda_model)\n",
    "        # convert to a dense vector\n",
    "        thetas_t = []\n",
    "        for theta_dist_t_sparse in thetas_t_sparse:\n",
    "            if not theta_dist_t_sparse:\n",
    "                continue\n",
    "            thetas_dist = convert_theta_sparse_to_dense_vector(theta_dist_t_sparse, 10)\n",
    "            thetas_t.append(thetas_dist)\n",
    "        # Get the mean theta\n",
    "        mean_theta_t = np.mean(thetas_t, axis=0)\n",
    "        mean_thetas[int(label)] = mean_theta_t\n",
    "        print(mean_thetas[int(label)])\n",
    "    return mean_thetas\n",
    "   \n",
    "mean_arr = get_doc_mean_topics()\n",
    "\n",
    "def plot_doc_topic_matrix():\n",
    "    # Get mean doc topics dists\n",
    "    mean_thetas = get_doc_mean_topics()\n",
    "    # Let's show a heatmap to see which topics occur the most for different labels\n",
    "    plt.imshow(mean_thetas)\n",
    "    plt.colorbar()\n",
    "    plt.xlabel(\"Topic ID\")\n",
    "    plt.ylabel(\"Class label\")\n",
    "    plt.show()\n",
    "plot_doc_topic_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43455c88",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_analytics",
   "language": "python",
   "name": "data_analytics"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
